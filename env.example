# Conference Talk Grace-Works Classifier Configuration
# Copy this file to .env and update the values

# ====================================
# REQUIRED SETTINGS
# ====================================

# OpenAI API Configuration
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# ====================================
# OPTIONAL SETTINGS
# ====================================

# OpenAI Model Configuration
# Supported models: gpt-4, gpt-4-turbo, gpt-3.5-turbo
# Note: gpt-4 provides better classification accuracy
OPENAI_MODEL=gpt-4

# Application Environment
# Options: development, staging, production
# Affects logging behavior and default settings
ENVIRONMENT=development

# ====================================
# LOGGING CONFIGURATION
# ====================================

# Logging Level
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
# DEBUG: Detailed information for diagnosing problems
# INFO: General information about program execution
# WARNING: Warning messages for potentially harmful situations
# ERROR: Error messages for serious problems
# CRITICAL: Critical error messages for very serious errors
LOG_LEVEL=INFO

# Log Format
# Options: console, json
# console: Human-readable format for development
# json: Structured JSON format for production monitoring
LOG_FORMAT=console

# Enable File Logging
# Options: true, false
# When enabled, logs are written to logs/ directory with rotation
ENABLE_FILE_LOGGING=true

# ====================================
# PROCESSING CONFIGURATION
# ====================================

# Rate Limiting
# Delay in seconds between API calls to respect OpenAI rate limits
# Recommended: 0.1 for development, 0.5+ for production with high volume
RATE_LIMIT_SECONDS=0.1

# Default Number of Talks to Process
# Set to 0 or leave empty to process all available talks
DEFAULT_NUM_TALKS=

# Batch Size for Incremental Saving
# Number of processed talks before saving intermediate results
# Helps prevent data loss during long processing sessions
BATCH_SAVE_SIZE=50

# ====================================
# FILE PATHS CONFIGURATION
# ====================================

# Input Directory
# Directory containing HTML files of conference talks
TALKS_INPUT_DIR=conference_talks

# Output Directory  
# Directory for generated CSV files and reports
OUTPUT_DIR=output

# Templates Directory
# Directory containing Jinja2 templates for prompts
TEMPLATES_DIR=templates

# Logs Directory
# Directory for log files (when file logging is enabled)
LOGS_DIR=logs

# ====================================
# CACHE CONFIGURATION
# ====================================

# Enable Classification Caching
# Options: true, false
# Caches classification results to avoid duplicate API calls
ENABLE_CACHING=true

# Cache Directory
# Directory for storing classification cache files
CACHE_DIR=.cache

# Cache Expiration (hours)
# How long cached results remain valid (0 = never expire)
CACHE_EXPIRATION_HOURS=168

# ====================================
# STREAMLIT DASHBOARD CONFIGURATION
# ====================================

# Dashboard Port
# Port for the Streamlit dashboard server
STREAMLIT_PORT=8501

# Dashboard Host
# Host address for the Streamlit dashboard
STREAMLIT_HOST=localhost

# Auto-refresh Interval (seconds)
# How often the dashboard refreshes data (0 = manual refresh only)
DASHBOARD_REFRESH_INTERVAL=300

# ====================================
# ADVANCED SETTINGS
# ====================================

# Maximum Retries for API Calls
# Number of retry attempts for failed OpenAI API calls
MAX_API_RETRIES=3

# API Timeout (seconds)
# Timeout for OpenAI API requests
API_TIMEOUT=60

# Memory Usage Optimization
# Options: true, false
# Enable memory optimization for large datasets
OPTIMIZE_MEMORY=false

# Debug Mode
# Options: true, false
# Enable additional debugging features and verbose output
DEBUG_MODE=false

# ====================================
# SECURITY SETTINGS
# ====================================

# Secure Mode
# Options: true, false
# Enables additional security validations
SECURE_MODE=true

# Input Validation Level
# Options: basic, strict, paranoid
# Level of input validation to perform
INPUT_VALIDATION=strict

# ====================================
# PERFORMANCE MONITORING
# ====================================

# Enable Performance Monitoring
# Options: true, false
# Tracks and logs performance metrics
ENABLE_PERFORMANCE_MONITORING=true

# Performance Logging Threshold (seconds)
# Log performance warnings for operations exceeding this duration
PERFORMANCE_THRESHOLD=5.0

# ====================================
# EXAMPLE CONFIGURATIONS
# ====================================

# Development Environment Example:
# ENVIRONMENT=development
# LOG_LEVEL=DEBUG
# LOG_FORMAT=console
# RATE_LIMIT_SECONDS=0.1
# DEBUG_MODE=true

# Production Environment Example:
# ENVIRONMENT=production
# LOG_LEVEL=INFO
# LOG_FORMAT=json
# RATE_LIMIT_SECONDS=0.5
# ENABLE_PERFORMANCE_MONITORING=true
# SECURE_MODE=true

# Testing Environment Example:
# ENVIRONMENT=testing
# LOG_LEVEL=WARNING
# ENABLE_CACHING=false
# MAX_API_RETRIES=1
# DEBUG_MODE=false

# ====================================
# NOTES
# ====================================

# 1. Environment variables take precedence over .env file values
# 2. Boolean values should be lowercase: true/false
# 3. Numeric values should not be quoted
# 4. File paths should use forward slashes, even on Windows
# 5. Keep your .env file private and never commit it to version control
# 6. Update env.example when adding new configuration options

# ====================================
# COST ESTIMATION
# ====================================

# Current OpenAI GPT-4 pricing (as of 2024):
# GPT-4: $2.00 per 1M input tokens + $8.00 per 1M output tokens
# GPT-4-turbo: Similar pricing structure
# GPT-3.5-turbo: Significantly lower cost
#
# Estimated costs per talk (average 6,000 input + 200 output tokens):
# GPT-4: ~$0.014 per talk
# GPT-3.5-turbo: ~$0.002 per talk
#
# For 1000 talks with GPT-4: ~$15
# For 1000 talks with GPT-3.5-turbo: ~$2
#
# Monitor your usage at: https://platform.openai.com/usage 