#!/usr/bin/env python3
"""
count_batch_tokens.py  â€“  Count tokens in an OpenAI Batch-API JSONL file.

Usage
-----
python count_batch_tokens.py batch_requests.jsonl \
    --encoding cl100k_base        # default for GPT-4-t-series, GPT-3.5-turbo
python count_batch_tokens.py batch_requests.jsonl \
    --model gpt-4o                # auto-selects the right encoding

Optional flags
--------------
--encoding ENCODING_NAME   Override with a specific tiktoken encoding
--model MODEL_NAME         Look up the correct encoding for a model
--stats                    Print per-line stats instead of just the total
"""
import argparse
import json
from pathlib import Path

import tiktoken


def get_token_count(text: str, enc) -> int:
    """Return the number of tokens in a text string for the given encoding."""
    return len(enc.encode(text))


def main():
    parser = argparse.ArgumentParser(description="Count tokens in an OpenAI Batch file")
    parser.add_argument("jsonl_path", type=Path, help="Path to batch_requests.jsonl")
    parser.add_argument("--encoding", help="tiktoken encoding name (e.g. cl100k_base)")
    parser.add_argument("--model", help="Model name to infer encoding (e.g. gpt-4o)")
    parser.add_argument("--stats", action="store_true", help="Show per-row statistics")
    args = parser.parse_args()

    # Determine which encoding to use
    if args.model:
        enc = tiktoken.encoding_for_model(args.model)
    else:
        enc = tiktoken.get_encoding(args.encoding or "cl100k_base")

    total_tokens = 0
    per_line = []

    with args.jsonl_path.open("r", encoding="utf-8") as f:
        for i, line in enumerate(f, start=1):
            obj = json.loads(line)
            text_to_tokenize = ""
            # Batch requests generated by classifier.py store the actual request in obj["body"]
            if "body" in obj and isinstance(obj["body"], dict) and "messages" in obj["body"]:
                messages = obj["body"]["messages"]
                if isinstance(messages, list):
                    text_to_tokenize = "".join(m.get("content", "") for m in messages if isinstance(m, dict))
            # Fallback for other common structures if needed, though less likely for this project
            elif "messages" in obj and isinstance(obj["messages"], list): # Original check, as a fallback
                text_to_tokenize = "".join(m.get("content", "") for m in obj["messages"] if isinstance(m, dict))
            elif "prompt" in obj and isinstance(obj["prompt"], str): # Original check for prompt
                text_to_tokenize = obj["prompt"]
            
            tok = get_token_count(text_to_tokenize, enc)
            total_tokens += tok
            per_line.append((i, tok))

    print(f"\nFile: {args.jsonl_path}")
    print(f"Total requests: {len(per_line)}")
    print(f"Total tokens:   {total_tokens:,}")

    if args.stats:
        # quick summary stats
        import statistics as st

        lengths = [t for _, t in per_line]
        print("\nToken stats per request:")
        print(f"  Mean: {st.mean(lengths):.1f}")
        print(f"  P95 : {st.quantiles(lengths, n=100)[94]:.0f}")
        print(f"  Max : {max(lengths)}")
        print(f"  Min : {min(lengths)}")

        print("\nFirst 10 lines (index, tokens):")
        for idx, tok in per_line[:10]:
            print(f"  {idx:>5}: {tok}")


if __name__ == "__main__":
    main()
